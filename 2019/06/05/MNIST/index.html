<!DOCTYPE html><html lang="en"><head><meta http-equiv="content-type" content="text/html; charset=utf-8"><meta content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=0" name="viewport"><meta content="yes" name="apple-mobile-web-app-capable"><meta content="black-translucent" name="apple-mobile-web-app-status-bar-style"><meta content="telephone=no" name="format-detection"><meta name="description"><title>Mnist学习 | 晟轩</title><link rel="stylesheet" type="text/css" href="/css/style.css?v=0.0.0"><link rel="stylesheet" type="text/css" href="//lib.baomitu.com/normalize/8.0.1/normalize.min.css"><link rel="stylesheet" type="text/css" href="//lib.baomitu.com/pure/1.0.0/pure-min.css"><link rel="stylesheet" type="text/css" href="//lib.baomitu.com/pure/1.0.0/grids-responsive-min.css"><link rel="stylesheet" href="//lib.baomitu.com/font-awesome/4.7.0/css/font-awesome.min.css"><script type="text/javascript" src="//lib.baomitu.com/jquery/3.3.1/jquery.min.js"></script><link rel="icon" mask="" sizes="any" href="/favicon.ico"><link rel="Shortcut Icon" type="image/x-icon" href="/favicon.ico"><link rel="apple-touch-icon" href="/apple-touch-icon.png"><link rel="apple-touch-icon-precomposed" href="/apple-touch-icon.png"><link rel="alternate" type="application/atom+xml" href="/atom.xml"><meta name="generator" content="Hexo 5.4.0"></head><body><div class="body_container"><div id="header"><div class="site-name"><h1 class="hidden">Mnist学习</h1><a id="logo" href="/.">晟轩</a><p class="description">尽是远方，不作归途</p></div><div id="nav-menu"><a class="current" href="/."><i class="fa fa-home"> Home</i></a><a href="/archives/"><i class="fa fa-archive"> Archive</i></a><a href="/about/"><i class="fa fa-user"> About</i></a><a href="/atom.xml"><i class="fa fa-rss"> RSS</i></a></div></div><div class="pure-g" id="layout"><div class="pure-u-1 pure-u-md-3-4"><div class="content_container"><div class="post"><h1 class="post-title">Mnist学习</h1><div class="post-meta">Jun 5, 2019<span> | </span><span class="category"><a href="/categories/%E6%9A%82%E6%97%B6%E6%B2%A1%E6%83%B3%E5%A5%BD%E5%90%8D%E5%AD%97/">暂时没想好名字</a></span></div><div class="post-content"><h3 id="Mnist-数据集操作"><a href="#Mnist-数据集操作" class="headerlink" title="Mnist 数据集操作"></a>Mnist 数据集操作</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">import numpy as np</span><br><span class="line">from keras.datasets import mnist</span><br><span class="line">from keras.models import Sequential, Model</span><br><span class="line">from keras.layers.core import Dense, Activation, Dropout</span><br><span class="line">from keras.utils import np_utils</span><br><span class="line"></span><br><span class="line">import matplotlib.pyplot as plt</span><br><span class="line">import matplotlib.image as processimage</span><br></pre></td></tr></table></figure>


<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">(X_train,Y_train),(X_test,Y_test) &#x3D; mnist.load_data()</span><br></pre></td></tr></table></figure>


<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">print X_test[9999].shape</span><br></pre></td></tr></table></figure>

<blockquote>
<p>(28L, 28L)</p>
</blockquote>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">plt.imshow(X_test[9996])</span><br></pre></td></tr></table></figure>




<blockquote>
<p>&lt;matplotlib.image.AxesImage at 0x194b2fd0&gt;</p>
</blockquote>
<p><img src="/images/output_3.png" alt="png"></p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">#reshape</span><br><span class="line">X_train &#x3D; X_train.reshape(60000,28*28)</span><br><span class="line">X_test &#x3D; X_test.reshape(10000,28*28)</span><br><span class="line">#set type into float32</span><br><span class="line">X_train &#x3D; X_train.astype(&#39;float32&#39;)</span><br><span class="line">X_test &#x3D; X_test.astype(&#39;float32&#39;)</span><br><span class="line">#归一化</span><br><span class="line">X_train &#x3D; X_train&#x2F;255</span><br><span class="line">X_test &#x3D; X_test&#x2F;255</span><br></pre></td></tr></table></figure>


<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">#Prepare basic seetups配置基本参数</span><br><span class="line">batch_size &#x3D; 1024 #每次进入神经网络的数据</span><br><span class="line">nb_class &#x3D; 10 #最终的分类数 0-9 10个数字</span><br><span class="line">nb_epochs &#x3D; 20 #training number训练次数</span><br></pre></td></tr></table></figure>


<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">#Class vectors [0,0,0,0,0,1,0,0,0,0]</span><br><span class="line">Y_test &#x3D; np_utils.to_categorical(Y_test,nb_class) #test dataset label</span><br><span class="line">Y_train &#x3D; np_utils.to_categorical(Y_train,nb_class)</span><br><span class="line">print Y_train[0] # 5</span><br></pre></td></tr></table></figure>

<blockquote>
<p>[0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]</p>
</blockquote>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">#设置网络结构</span><br><span class="line">model &#x3D; Sequential()</span><br><span class="line"></span><br><span class="line">#1st layer</span><br><span class="line">model.add(Dense(512,input_shape &#x3D; (784 ,))) #28*28--&gt;512   ## ,不能忘了</span><br><span class="line">model.add(Activation(&#39;relu&#39;)) #激活函数</span><br><span class="line">model.add(Dropout(0.2)) #dropout避免过拟合</span><br><span class="line"></span><br><span class="line">#2nd layer</span><br><span class="line">model.add(Dense(256))</span><br><span class="line">model.add(Activation(&#39;relu&#39;))</span><br><span class="line">model.add(Dropout(0.2))</span><br><span class="line"></span><br><span class="line">#3rd layer</span><br><span class="line">model.add(Dense(10)) #类别数</span><br><span class="line">model.add(Activation(&#39;softmax&#39;)) #softmax 根据10进行分类</span><br></pre></td></tr></table></figure>


<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">#Compile 编译</span><br><span class="line">model.compile(</span><br><span class="line">    loss &#x3D; &#39;categorical_crossentropy&#39;, #损失函数</span><br><span class="line">    optimizer &#x3D; &#39;rmsprop&#39;, #优化，adam,SGD</span><br><span class="line">    metrics &#x3D; [&#39;accuracy&#39;]   </span><br><span class="line">)</span><br></pre></td></tr></table></figure>


<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">#启动网络训练</span><br><span class="line">Trainning &#x3D; model.fit(</span><br><span class="line">    X_train,Y_train, #训练数据</span><br><span class="line">    batch_size &#x3D; batch_size, </span><br><span class="line">    epochs &#x3D; nb_epochs, #训练次数</span><br><span class="line">    validation_data &#x3D; (X_test, Y_test)</span><br><span class="line">)</span><br></pre></td></tr></table></figure>
<blockquote>
<p>  Train on 60000 samples, validate on 10000 samples<br>    Epoch 1/20<br>    60000/60000 [==============================] - 5s 80us/step - loss: 0.5399 - acc: 0.8309 - val_loss: 0.3003 - val_acc: 0.9027<br>    Epoch 2/20<br>    60000/60000 [==============================] - 5s 77us/step - loss: 0.2152 - acc: 0.9353 - val_loss: 0.1491 - val_acc: 0.9546<br>    Epoch 3/20<br>    60000/60000 [==============================] - 5s 77us/step - loss: 0.1481 - acc: 0.9548 - val_loss: 0.1205 - val_acc: 0.9611<br>    Epoch 4/20<br>    60000/60000 [==============================] - 5s 77us/step - loss: 0.1105 - acc: 0.9665 - val_loss: 0.0941 - val_acc: 0.9695<br>    Epoch 5/20<br>    60000/60000 [==============================] - 5s 77us/step - loss: 0.0879 - acc: 0.9724 - val_loss: 0.1016 - val_acc: 0.9665<br>    Epoch 6/20<br>    60000/60000 [==============================] - 5s 78us/step - loss: 0.0706 - acc: 0.9782 - val_loss: 0.0713 - val_acc: 0.9759<br>    Epoch 7/20<br>    60000/60000 [==============================] - 5s 77us/step - loss: 0.0577 - acc: 0.9813 - val_loss: 0.0687 - val_acc: 0.9795<br>    Epoch 8/20<br>    60000/60000 [==============================] - 5s 77us/step - loss: 0.0504 - acc: 0.9839 - val_loss: 0.0749 - val_acc: 0.9756<br>    Epoch 9/20<br>    60000/60000 [==============================] - 5s 77us/step - loss: 0.0405 - acc: 0.9870 - val_loss: 0.0693 - val_acc: 0.9795<br>    Epoch 10/20<br>    60000/60000 [==============================] - 5s 77us/step - loss: 0.0362 - acc: 0.9885 - val_loss: 0.0611 - val_acc: 0.9803<br>    Epoch 11/20<br>    60000/60000 [==============================] - 5s 77us/step - loss: 0.0306 - acc: 0.9903 - val_loss: 0.0694 - val_acc: 0.9812<br>    Epoch 12/20<br>    60000/60000 [==============================] - 5s 78us/step - loss: 0.0241 - acc: 0.9923 - val_loss: 0.0650 - val_acc: 0.9803<br>    Epoch 13/20<br>    60000/60000 [==============================] - 5s 77us/step - loss: 0.0237 - acc: 0.9924 - val_loss: 0.0631 - val_acc: 0.9822<br>    Epoch 14/20<br>    60000/60000 [==============================] - 5s 77us/step - loss: 0.0200 - acc: 0.9937 - val_loss: 0.0621 - val_acc: 0.9823<br>    Epoch 15/20<br>    60000/60000 [==============================] - 5s 78us/step - loss: 0.0185 - acc: 0.9939 - val_loss: 0.0666 - val_acc: 0.9824<br>    Epoch 16/20<br>    60000/60000 [==============================] - 5s 78us/step - loss: 0.0161 - acc: 0.9944 - val_loss: 0.0645 - val_acc: 0.9813<br>    Epoch 17/20<br>    60000/60000 [==============================] - 5s 77us/step - loss: 0.0147 - acc: 0.9956 - val_loss: 0.0637 - val_acc: 0.9826<br>    Epoch 18/20<br>    60000/60000 [==============================] - 5s 77us/step - loss: 0.0139 - acc: 0.9954 - val_loss: 0.0617 - val_acc: 0.9831<br>    Epoch 19/20<br>    60000/60000 [==============================] - 5s 77us/step - loss: 0.0128 - acc: 0.9955 - val_loss: 0.0705 - val_acc: 0.9819<br>    Epoch 20/20<br>    60000/60000 [==============================] - 5s 77us/step - loss: 0.0112 - acc: 0.9964 - val_loss: 0.0760 - val_acc: 0.9806</p>
</blockquote>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">#显示test中的图</span><br><span class="line">#testrun &#x3D; X_test[9993].shape</span><br><span class="line">testrun &#x3D; X_test[9991].reshape(1,784)</span><br><span class="line">testlabel &#x3D; Y_test[9991]</span><br><span class="line">print testlabel</span><br><span class="line">plt.imshow(testrun.reshape([28,28]))</span><br></pre></td></tr></table></figure>

<blockquote>
<p>[0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]<br>  &lt;matplotlib.image.AxesImage at 0x26a31668&gt;</p>
</blockquote>
<p><img src="/images/output_8.png" alt="png"></p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">#判定输出结果</span><br><span class="line">predict &#x3D; model.predict(testrun)</span><br><span class="line">print predict</span><br><span class="line">print &#39;***************************&#39;</span><br><span class="line">print [final.argmax() for final in predict]</span><br></pre></td></tr></table></figure>
<blockquote>
<p>[[2.1115665e-07 2.5541942e-07 6.0587092e-07 2.2769389e-06 9.0447577e-10<br>  3.0733561e-06 4.2453201e-09 1.0392086e-08 9.9999332e-01 2.0773830e-07]]</p>
</blockquote>
<hr>
<p>  [8]</p>
</div><div class="tags"><a href="/tags/Keras/">Keras</a><a href="/tags/Deep-Learning/">Deep Learning</a></div><div class="post-nav"><a class="next" href="/2019/03/19/%E6%95%91%E8%B5%8E%E4%B9%8B%E6%97%85/">救赎之旅</a></div></div></div></div><div class="pure-u-1-4 hidden_mid_and_down"><div id="sidebar"><div class="widget"><form class="search-form" action="//www.google.com/search" method="get" accept-charset="utf-8" target="_blank"><input type="text" name="q" maxlength="20" placeholder="Search"/><input type="hidden" name="sitesearch" value="http://yoursite.com"/></form></div><div class="widget"><div class="widget-title"><i class="fa fa-folder-o"> Categories</i></div><ul class="category-list"><li class="category-list-item"><a class="category-list-link" href="/categories/%E6%9A%82%E6%97%B6%E6%B2%A1%E6%83%B3%E5%A5%BD%E5%90%8D%E5%AD%97/">暂时没想好名字</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/%E9%9A%8F%E7%AC%94/">随笔</a></li></ul></div><div class="widget"><div class="widget-title"><i class="fa fa-star-o"> Tags</i></div><div class="tagcloud"><a href="/tags/hello/" style="font-size: 15px;">hello</a> <a href="/tags/hexo/" style="font-size: 15px;">hexo</a> <a href="/tags/Keras/" style="font-size: 15px;">Keras</a> <a href="/tags/Deep-Learning/" style="font-size: 15px;">Deep Learning</a> <a href="/tags/Life/" style="font-size: 15px;">Life</a></div></div><div class="widget"><div class="widget-title"><i class="fa fa-file-o"> Recent</i></div><ul class="post-list"><li class="post-list-item"><a class="post-list-link" href="/2019/06/05/MNIST/">Mnist学习</a></li><li class="post-list-item"><a class="post-list-link" href="/2019/03/19/%E6%95%91%E8%B5%8E%E4%B9%8B%E6%97%85/">救赎之旅</a></li><li class="post-list-item"><a class="post-list-link" href="/2019/02/22/%E6%91%86%E6%AD%A3%E5%BF%83%E6%80%81/">摆正心态</a></li><li class="post-list-item"><a class="post-list-link" href="/2019/01/14/Hexo%E6%9B%B4%E6%8D%A2%E7%94%B5%E8%84%91/">Hexo博客更换电脑的解决办法</a></li><li class="post-list-item"><a class="post-list-link" href="/2018/10/03/hello-world/">Hello World</a></li><li class="post-list-item"><a class="post-list-link" href="/2018/01/29/hello-World-0/">hello World</a></li></ul></div><div class="widget"><div class="widget-title"><i class="fa fa-external-link"> Links</i></div><ul></ul><a href="http://www.example1.com/" title="site-name1" target="_blank">site-name1</a><ul></ul><a href="http://www.example2.com/" title="site-name2" target="_blank">site-name2</a><ul></ul><a href="http://www.example3.com/" title="site-name3" target="_blank">site-name3</a></div></div></div><div class="pure-u-1 pure-u-md-3-4"><div id="footer">Copyright © 2021 <a href="/." rel="nofollow">晟轩.</a> Powered by<a rel="nofollow" target="_blank" href="https://hexo.io"> Hexo.</a><a rel="nofollow" target="_blank" href="https://github.com/tufu9441/maupassant-hexo"> Theme</a> by<a rel="nofollow" target="_blank" href="https://github.com/pagecho"> Cho.</a></div></div></div><a class="show" id="rocket" href="#top"></a><script type="text/javascript" src="/js/totop.js?v=0.0.0" async></script><script type="text/javascript" src="//lib.baomitu.com/fancybox/3.5.2/jquery.fancybox.min.js" async></script><script type="text/javascript" src="/js/fancybox.js?v=0.0.0" async></script><link rel="stylesheet" type="text/css" href="//lib.baomitu.com/fancybox/3.5.2/jquery.fancybox.min.css"><script type="text/javascript" src="/js/codeblock-resizer.js?v=0.0.0"></script><script type="text/javascript" src="/js/smartresize.js?v=0.0.0"></script></div></body></html>